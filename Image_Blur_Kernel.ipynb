{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jluVlac1qXY1",
        "outputId": "03cf45cd-4967-4e00-e452-1e490a494592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (1.11.1.1)\n"
          ]
        }
      ],
      "source": [
        "pip install ninja"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile blur.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<math.h>\n",
        "#include <c10/cuda/CUDAException.h>\n",
        "#include <c10/cuda/CUDAStream.h>\n",
        "#include<torch/torch.h>\n",
        "\n",
        "\n",
        "\n",
        "#define BLUR 1 //3x3 blur filter\n",
        "\n",
        "__global__\n",
        "void blurKernel(unsigned char* output, unsigned char* input, int width, int height)\n",
        "{\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int channel = threadIdx.z;\n",
        "\n",
        "    int baseOffset = channel * height * width;\n",
        "    if (col < width && row < height) {\n",
        "\n",
        "        int pixVal = 0;\n",
        "        int pixels = 0;\n",
        "\n",
        "        for (int blurRow=-BLUR; blurRow <= BLUR; blurRow += 1) {\n",
        "            for (int blurCol=-BLUR; blurCol <= BLUR; blurCol += 1) {\n",
        "                int curRow = row + blurRow;\n",
        "                int curCol = col + blurCol;\n",
        "                if (curRow >= 0 && curRow < height && curCol >=0 && curCol < width) {\n",
        "                    pixVal += input[baseOffset + curRow * width + curCol];\n",
        "                    pixels += 1;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        output[baseOffset + row * width + col] = (unsigned char)(pixVal / pixels);\n",
        "    }\n",
        "    return;\n",
        "}\n",
        "\n",
        "torch::Tensor blur(torch::Tensor image){\n",
        "  const auto channels = image.size(0);\n",
        "  const auto height = image.size(1);\n",
        "  const auto width = image.size(2);\n",
        "  //Create output tensor, set dtype as unsigned int 8 bits and set device as image's device\n",
        "  auto result = torch::empty_like(image);\n",
        "  dim3 threads_per_block(16, 16, channels);\n",
        "  dim3 number_of_blocks(ceil(width/ 16.0),ceil(height/ 16.0));\n",
        "  //launch the kernel, 0 is the shared memory size per block and getCurrentCUDAStream() is the stream to use for the kernel ensuring kernel executes in current stream\n",
        "  blurKernel<<<number_of_blocks, threads_per_block, 0, at::cuda::getCurrentCUDAStream()>>>(\n",
        "        result.data_ptr<unsigned char>(),\n",
        "        image.data_ptr<unsigned char>(),\n",
        "        width,\n",
        "        height\n",
        "    );\n",
        "  //Macro for cuda error checks\n",
        "  C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "  return result;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDpNmvnjqced",
        "outputId": "dc855549-0e0c-41ea-eec4-58cd307230fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting blur.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o blur_extension.so blur.cu -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/cuda/include -L/usr/local/cuda/lib64 -lcudart -lc10 -ltorch -ltorch_cpu -ltorch_cuda -shared -std=c++11 -Xcompiler -fPIC -O2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOtC41QVu-lw",
        "outputId": "025d8583-4411-431f-e7c8-ecaede94312d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kblur.cu:6\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4:2:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K#error C++17 or later compatible compiler is required to use PyTorch.\n",
            "    4 | #\u001b[01;31m\u001b[Kerror\u001b[m\u001b[K C++17 or later compatible compiler is required to use PyTorch.\n",
            "      |  \u001b[01;31m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/detail/config/config.h:27\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/complex.h:24\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:15\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kblur.cu:6\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/thrust/detail/config/cpp_dialect.h:131:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  131 |      THRUST_\u001b[01;35m\u001b[KCOMPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                           \n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cub/util_arch.cuh:36\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/cub/util_debug.cuh:40\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/system/cuda/config.h:43\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/system/cuda/detail/execution_policy.h:35\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/iterator/detail/device_system_tag.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/iterator/iterator_traits.h:62\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/detail/type_traits/pointer_traits.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/detail/raw_pointer_cast.h:20\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/type_traits/is_contiguous_iterator.h:26\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/type_traits/is_trivially_relocatable.h:29\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/detail/complex/complex.inl:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/complex.h:1036\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/complex.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Half.h:15\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/Float8_e5m2.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/ScalarType.h:8\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/core/Scalar.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:16\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kblur.cu:6\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cub/util_cpp_dialect.cuh:142:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KCUB requires at least C++14. C++11 is deprecated but still supported. C++11 support will be removed in a future release. Define CUB_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "  142 |      CUB_COM\u001b[01;35m\u001b[KPILER_DEPRECATION_SOFT(C++14, C++11);\u001b[m\u001b[K\n",
            "      |             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                                                                                                        \n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBase.h:14\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:38\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kblur.cu:6\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/c10/util/C++17.h:24:2:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K#error You need C++17 to compile PyTorch\n",
            "   24 | #\u001b[01;31m\u001b[Kerror\u001b[m\u001b[K You need C++17 to compile PyTorch\n",
            "      |  \u001b[01;31m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kblur.cu:6\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:4:2:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K#error C++17 or later compatible compiler is required to use ATen.\n",
            "    4 | #\u001b[01;31m\u001b[Kerror\u001b[m\u001b[K C++17 or later compatible compiler is required to use ATen.\n",
            "      |  \u001b[01;31m\u001b[K^~~~~\u001b[m\u001b[K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "from torchvision.io import read_image, write_png\n",
        "from torch.utils.cpp_extension import load_inline\n",
        "\n",
        "def compile_extension():\n",
        "    #this is the source for cuda kernel code(runs on gpu)\n",
        "    cuda_source = Path(\"blur.cu\").read_text()\n",
        "    #this is the source for non cuda kernel code(runs on host) that is the wrapper function\n",
        "    cpp_source = \"torch::Tensor blur(torch::Tensor image);\"\n",
        "\n",
        "    # Load the CUDA kernel as a PyTorch extension\n",
        "    blur_extension = load_inline(\n",
        "        name=\"blur_extension\",\n",
        "        cpp_sources=cpp_source,\n",
        "        cuda_sources=cuda_source,\n",
        "        # this is the wrapper function calling the CUDA kernel\n",
        "        functions=[\"blur\"],\n",
        "        with_cuda=True,\n",
        "        extra_cuda_cflags=[\"-O2\"],\n",
        "        #build_directory='./cuda_build'\n",
        "    )\n",
        "    return blur_extension"
      ],
      "metadata": {
        "id": "AxXbS517vYZ5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Load the extension\n",
        "    ext = compile_extension()\n",
        "    x = read_image(\"test.jpg\").contiguous().cuda()\n",
        "    y = ext.blur(x)\n",
        "    write_png(y.cpu(), \"output.png\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YlMg6OgwLhm",
        "outputId": "7daf3a93-0bbd-4fa6-dd0b-7686f9feacef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 800, 1200])\n"
          ]
        }
      ]
    }
  ]
}